from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.responses import PlainTextResponse
import pandas as pd
import duckdb
from openai import OpenAI
import os
import re
from io import BytesIO
from dotenv import load_dotenv

load_dotenv()

app = FastAPI()

# Temporary storage for DataFrames
dataframes = {}

# Initialize OpenAI client
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def get_schema():
    schema = []
    for table_name, df in dataframes.items():
        columns = [f"{col} ({dtype})" for col, dtype in zip(df.columns, df.dtypes)]
        schema.append(f"Table {table_name} ({', '.join(columns)})")
    return "\n".join(schema)

def extract_sql(text: str) -> str:
    """Extract SQL code from markdown code blocks"""
    match = re.search(r"```sql\n(.*?)\n```", text, re.DOTALL)
    return match.group(1).strip() if match else text.strip()

@app.post("/upload/")
async def upload_files(files: list[UploadFile] = File(...)):
    """Endpoint to upload CSV/Excel files"""
    try:
        for file in files:
            content = await file.read()
            
            if file.filename.endswith('.csv'):
                df = pd.read_csv(BytesIO(content))
                table_name = file.filename[:-4]
                dataframes[table_name] = df
                
            elif file.filename.endswith(('.xls', '.xlsx')):
                xls = pd.ExcelFile(BytesIO(content))
                base_name = file.filename.rsplit('.', 1)[0]
                
                for sheet_name in xls.sheet_names:
                    df = xls.parse(sheet_name)
                    table_name = f"{base_name}_{sheet_name}"
                    dataframes[table_name] = df
                    
            else:
                raise ValueError("Unsupported file format")
            
        return {"message": f"Successfully processed {len(files)} files"}
    
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.post("/query/")
async def process_query(prompt: str):
    """Endpoint to process natural language query"""
    if not dataframes:
        raise HTTPException(status_code=400, detail="Upload files first")
    
    try:
        # Generate schema description
        schema = get_schema()
        
        # Create LLM prompt
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": f"""You are a SQL expert. Convert the user's query into SQL using these tables:
                {schema}
                - Use exact table/column names from the schema
                - Return only SQL code without explanations
                - Use standard SQL syntax"""},
                {"role": "user", "content": prompt}
            ]
        )
        
        # Extract SQL from response
        generated_sql = extract_sql(response.choices[0].message.content)
        
        # Execute query using DuckDB
        conn = duckdb.connect()
        for table_name, df in dataframes.items():
            conn.register(table_name, df)
            
        result = conn.execute(generated_sql).fetchdf()
        
        return PlainTextResponse(result.to_markdown(index=False))
    
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Error processing query: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
